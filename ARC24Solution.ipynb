{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":7.062079,"end_time":"2024-07-26T11:11:43.224411","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-26T11:11:36.162332","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import colors\nimport json\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.176166,"end_time":"2024-07-26T11:11:41.248828","exception":false,"start_time":"2024-07-26T11:11:39.072662","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-08T12:34:39.844356Z","iopub.execute_input":"2024-08-08T12:34:39.844806Z","iopub.status.idle":"2024-08-08T12:34:44.558060Z","shell.execute_reply.started":"2024-08-08T12:34:39.844770Z","shell.execute_reply":"2024-08-08T12:34:44.557002Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n/kaggle/input/arc-prize-2024/sample_submission.json\n/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_json_file(path):\n    with open(path) as file:\n        return json.load(file)\n\neval_challenges = load_json_file(\"/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\")\neval_solutions = load_json_file(\"/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\")\ntest_challenges = load_json_file(\"/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\")\ntrain_challenges = load_json_file(\"/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\")\ntrain_solutions = load_json_file(\"/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\")","metadata":{"papermill":{"duration":0.284477,"end_time":"2024-07-26T11:11:41.536343","exception":false,"start_time":"2024-07-26T11:11:41.251866","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-08T12:35:07.625235Z","iopub.execute_input":"2024-08-08T12:35:07.626191Z","iopub.status.idle":"2024-08-08T12:35:08.061464Z","shell.execute_reply.started":"2024-08-08T12:35:07.626154Z","shell.execute_reply":"2024-08-08T12:35:08.060211Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cmap = colors.ListedColormap(['black', 'blue', 'red', 'green', 'yellow', 'gray', 'magenta', 'orange', 'cyan', 'brown'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n\ndef plot_task(task, task_solution=None):\n    n_train_pairs = len(task['train'])\n    n_test_pairs = len(task['test'])\n    \n    fig, axs = plt.subplots(n_train_pairs + n_test_pairs, 2, figsize=(5, 5 * (n_train_pairs + n_test_pairs)))\n    fig.suptitle('Task')\n    \n    for i in range(n_train_pairs):\n        axs[i, 0].imshow(task['train'][i]['input'], cmap=cmap, norm=norm)\n        axs[i, 0].set_title('Train Input')\n        axs[i, 0].axis('off')\n        \n        axs[i, 1].imshow(task['train'][i]['output'], cmap=cmap, norm=norm)\n        axs[i, 1].set_title('Train Output')\n        axs[i, 1].axis('off')\n            \n    for i in range(n_test_pairs):\n        axs[n_train_pairs + i, 0].imshow(task['test'][i]['input'], cmap=cmap, norm=norm)\n        axs[n_train_pairs + i, 0].set_title('Test Input')\n        axs[n_train_pairs + i, 0].axis('off')\n        \n        if 'output' in task['test'][i]:\n            axs[n_train_pairs + i, 1].imshow(task['test'][i]['output'], cmap=cmap, norm=norm)\n            axs[n_train_pairs + i, 1].set_title('Test Output (Ground Truth)')\n        elif task_solution:\n            axs[n_train_pairs + i, 1].imshow(task_solution, cmap=cmap, norm=norm)\n            axs[n_train_pairs + i, 1].set_title('Test Output (Predicted)')\n            \n        axs[n_train_pairs + i, 1].axis('off')\n             \n    plt.show()","metadata":{"papermill":{"duration":0.021377,"end_time":"2024-07-26T11:11:41.560550","exception":false,"start_time":"2024-07-26T11:11:41.539173","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-08T12:36:56.866684Z","iopub.execute_input":"2024-08-08T12:36:56.867136Z","iopub.status.idle":"2024-08-08T12:36:56.882141Z","shell.execute_reply.started":"2024-08-08T12:36:56.867103Z","shell.execute_reply":"2024-08-08T12:36:56.880762Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Remove the condition if you want to execute this blcok.\nif 1 == 0:\n    for task_id, task in train_challenges.items():\n        solutions = train_solutions.get(task_id, [])\n        if solutions:\n            for solution in solutions:\n                plt.figure()\n                plot_task(task, solution)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T12:42:28.696016Z","iopub.execute_input":"2024-08-08T12:42:28.696442Z","iopub.status.idle":"2024-08-08T12:42:28.702694Z","shell.execute_reply.started":"2024-08-08T12:42:28.696409Z","shell.execute_reply":"2024-08-08T12:42:28.701441Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Remove the condition if you want to execute this blcok.\nif 1 == 0:\n    example_task = train_challenges['007bbfb7']\n    example_solution = train_solutions['007bbfb7'][0]\n    print(example_task, example_solution)\n    plot_task(example_task, example_solution)","metadata":{"papermill":{"duration":1.036186,"end_time":"2024-07-26T11:11:42.599618","exception":false,"start_time":"2024-07-26T11:11:41.563432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-03T08:50:06.618006Z","iopub.execute_input":"2024-08-03T08:50:06.618435Z","iopub.status.idle":"2024-08-03T08:50:07.886536Z","shell.execute_reply.started":"2024-08-03T08:50:06.618401Z","shell.execute_reply":"2024-08-03T08:50:07.885235Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom dataset class\nclass ReasoningDataset(Dataset):\n    def __init__(self, data, train=True):\n        self.data = data['train'] if train else data['test']\n        self.train = train\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        input_image = torch.tensor(self.data[idx]['input'], dtype=torch.float32).unsqueeze(0) / 7.0\n        if self.train:\n            output_image = torch.tensor(self.data[idx]['output'], dtype=torch.float32).unsqueeze(0) / 7.0\n            return input_image, output_image\n        else:\n            return input_image","metadata":{"execution":{"iopub.status.busy":"2024-08-03T08:52:42.230322Z","iopub.execute_input":"2024-08-03T08:52:42.230805Z","iopub.status.idle":"2024-08-03T08:52:42.239923Z","shell.execute_reply.started":"2024-08-03T08:52:42.230758Z","shell.execute_reply":"2024-08-03T08:52:42.238575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNReasoningModel(nn.Module):\n    def __init__(self):\n        super(CNNReasoningModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.upsample = nn.Upsample(scale_factor=3, mode='bilinear', align_corners=True)\n        self.conv4 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n        self.conv6 = nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = torch.relu(self.conv2(x))\n        x = torch.relu(self.conv3(x))\n        x = self.upsample(x)\n        x = torch.relu(self.conv4(x))\n        x = torch.relu(self.conv5(x))\n        x = torch.sigmoid(self.conv6(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-03T08:58:07.760582Z","iopub.execute_input":"2024-08-03T08:58:07.761037Z","iopub.status.idle":"2024-08-03T08:58:07.844782Z","shell.execute_reply.started":"2024-08-03T08:58:07.761004Z","shell.execute_reply":"2024-08-03T08:58:07.843359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nbatch_size = 2\nlearning_rate = 0.001\nnum_epochs = 10\n\n\n# Create datasets and dataloaders\ntrain_dataset = ReasoningDataset(data, train=True)\ntest_dataset = ReasoningDataset(data, train=False)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# Initialize the model, loss function, and optimizer\nmodel = CNNReasoningModel()\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, targets in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n\nprint(\"Training Complete\")\n\n# Testing loop (predict outputs for test inputs)\nmodel.eval()\ntest_results = []\nwith torch.no_grad():\n    for inputs in test_loader:\n        outputs = model(inputs)\n        test_results.append(outputs.squeeze(0).squeeze(0).numpy())\n\nprint(\"Testing Complete\")","metadata":{},"execution_count":null,"outputs":[]}]}